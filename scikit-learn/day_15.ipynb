{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd022020",
   "metadata": {},
   "source": [
    "DAY 15 — Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdcd32a",
   "metadata": {},
   "source": [
    "* So far your models, Decision Tree and Random Forest worked like flowcharts. Ask yes/no questions, follow branches, reach a conclusion.\n",
    "* Logistic Regression works completely differently. Instead of flowcharts it uses mathematics and probability to make predictions.\n",
    "* It answers a different question than \"survived or died.\" It answers — \"what is the probability that this person survived?\"\n",
    "* If probability > 0.5 → predict SURVIVED\n",
    "* If probability < 0.5 → predict DIED\n",
    "* This is powerful because you don't just get a yes/no answer — you get a confidence score. \"This passenger has 89% chance of survival\" is much more useful than just \"survived.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40cc7d5",
   "metadata": {},
   "source": [
    " TOPIC 1 — Linear Regression First (Quick Background)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c51c73",
   "metadata": {},
   "source": [
    "To understand Logistic Regression you need to briefly understand Linear Regression.\n",
    "\n",
    "Linear Regression draws a straight line through your data to predict a continuous number like predicting house price based on size\n",
    "* Price = (weight × size) + bias\n",
    "\n",
    "The model finds the best weight and bias values that make the line fit the data as closely as possible\n",
    "\n",
    "But here's the problem if you try to use a straight line to predict survival (0 or 1), the line can give you values like -0.3 or 1.7. Those aren't valid probabilities. Probability must stay between 0 and 1.\n",
    "\n",
    "This is the exact problem Logistic Regression solves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2a9c1b",
   "metadata": {},
   "source": [
    "TOPIC 2 — The Sigmoid Function\n",
    ">Logistic Regression takes the straight line output and squashes it into a value between 0 and 1 using something called the sigmoid function.\n",
    "\n",
    "No matter what number you feed into sigmoid — even -1000 or +1000 — the output always comes out between 0 and 1. That's the magic.\n",
    "\n",
    "* Very negative input → output close to 0 (definitely died)\n",
    "* Very positive input → output close to 1 (definitely survived)\n",
    "* Input near 0 → output near 0.5 (uncertain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaee804",
   "metadata": {},
   "source": [
    "So Logistic Regression does this:\n",
    "* Step 1:Calculate linear score = (w1 × Pclass) + (w2 × Age) + (w3 × Sex) + ... + bias\n",
    "* Step 2: Feed score into sigmoid → get probability between 0 and 1\n",
    "* Step 3: If probability > 0.5 → predict SURVIVED, else DIED\n",
    "\n",
    "The model learns the best weights (w1, w2, w3...) during training so that the probabilities it outputs match the actual outcomes as closely as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2871f6ed",
   "metadata": {},
   "source": [
    "TOPIC 3 — Building Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c2afbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.92224675 0.07775325]\n",
      " [0.76068133 0.23931867]\n",
      " [0.85081204 0.14918796]\n",
      " [0.0995168  0.9004832 ]\n",
      " [0.31950612 0.68049388]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Titanic.csv\")\n",
    "\n",
    "df[\"Sex\"] = df[\"Sex\"].map({\"male\": 0, \"female\": 1})\n",
    "X = df[[\"Pclass\", \"Age\", \"Sex\", \"Fare\", \"SibSp\", \"Parch\"]] \n",
    "y = df[\"Survived\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create\n",
    "model_lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "# max_iter=1000 — how many times the model adjusts weights during training\n",
    "# default is 100 which sometimes isn't enough — 1000 is safe\n",
    "\n",
    "# Train\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict classes (0 or 1)\n",
    "predictions = model_lr.predict(X_test)\n",
    "\n",
    "# Predict probabilities — this is unique to Logistic Regression\n",
    "probabilities = model_lr.predict_proba(X_test)\n",
    "print(probabilities[:5])\n",
    "# Output: [[0.82, 0.18],   — 82% chance died, 18% survived\n",
    "#          [0.21, 0.79],   — 21% chance died, 79% survived\n",
    "#          ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2160b08f",
   "metadata": {},
   "source": [
    "predict_proba() is the powerful method Decision Trees don't give you cleanly. Each row has two numbers — probability of dying and probability of surviving. They always add up to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1600cea4",
   "metadata": {},
   "source": [
    "TOPIC 4 — Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbb060f",
   "metadata": {},
   "source": [
    "Here's something important that Logistic Regression needs but Decision Trees don't, \"feature scaling\".\n",
    "\n",
    "Look at your features:\n",
    "\n",
    "* Age: values between 0 and 80\n",
    "* Fare: values between 0 and 500\n",
    "* Pclass: values between 1 and 3\n",
    "\n",
    "Fare has much larger numbers than Pclass. In Logistic Regression this matters — the model uses weights and mathematics, so a feature with larger numbers can dominate the calculation unfairly just because of its scale, not because it's actually more important.\n",
    "\n",
    "The fix is StandardScaler — it transforms each feature to have mean=0 and standard deviation=1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bb410fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training data only — learn the mean and std from training\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform test data using the same scaler — never fit on test data\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6bad8a",
   "metadata": {},
   "source": [
    "* Critical rule — you fit the scaler ONLY on training data. Then use that same scaler to transform test data. If you fit on test data too, you're leaking information about the test set into your model — called data leakage — and your accuracy becomes unreliable.\n",
    "\n",
    "* Think of it like this — you measure the average height of your class (training data) and use that as your reference. When a new student joins (test data) you measure them using the same reference — not a new one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e781bc4",
   "metadata": {},
   "source": [
    "TOPIC 5 — Comparing All Three Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f802889d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: 75.42%\n",
      "Random Forest: 80.45%\n",
      "Logistic Regression: 81.01%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Decision Tree from Day 13\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "dt_pred = dt.predict(X_test)\n",
    "dt_accuracy = accuracy_score(y_test, dt_pred)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "\n",
    "#logistic reasoning\n",
    "lr_pred = model_lr.predict(X_test)\n",
    "lr_accuracy = accuracy_score(y_test, lr_pred)\n",
    "results = {\n",
    "    \"Decision Tree\": dt_accuracy,\n",
    "    \"Random Forest\": rf_accuracy,\n",
    "    \"Logistic Regression\": lr_accuracy\n",
    "}\n",
    "\n",
    "for model_name, accuracy in results.items():\n",
    "    print(f\"{model_name}: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8db7aa",
   "metadata": {},
   "source": [
    "No single model is always best. It depends on your data, your problem, and your priorities. Comparing multiple models and picking the best one for your specific problem is called model selection — a key skill in ML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fe8477",
   "metadata": {},
   "source": [
    "TOPIC 6 — The Coefficients — What Did the Model Learn?\n",
    "\n",
    "Unlike Decision Trees which give feature importance, Logistic Regression gives you coefficients the weights it assigned to each feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b72ff4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature  Coefficient\n",
      "2     Sex     2.611261\n",
      "3    Fare     0.003422\n",
      "1     Age    -0.032004\n",
      "5   Parch    -0.129331\n",
      "4   SibSp    -0.317606\n",
      "0  Pclass    -0.927792\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    \"Feature\": [\"Pclass\", \"Age\", \"Sex\", \"Fare\", \"SibSp\", \"Parch\"],\n",
    "    \"Coefficient\": model_lr.coef_[0]\n",
    "}).sort_values(\"Coefficient\", ascending=False)\n",
    "\n",
    "print(coef_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e228ec3",
   "metadata": {},
   "source": [
    "* Positive coefficient — higher value of this feature increases survival probability.\n",
    "* Negative coefficient — higher value of this feature decreases survival probability.\n",
    "* Sex should have a large positive coefficient — being female (1) strongly increases survival probability. Pclass should have a negative coefficient — higher class number (3rd class) decreases survival probability.\n",
    "* This is interpretability — understanding exactly what your model learned and why it makes each prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26af49cd",
   "metadata": {},
   "source": [
    "Task 1 — Build Logistic Regression (20 mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dab8ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 79.89%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.86      0.83       105\n",
      "           1       0.78      0.72      0.75        74\n",
      "\n",
      "    accuracy                           0.80       179\n",
      "   macro avg       0.80      0.79      0.79       179\n",
      "weighted avg       0.80      0.80      0.80       179\n",
      "\n",
      "Random forest accuracy, 0.7988826815642458\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=10,random_state=42)\n",
    "\n",
    "# Build and train\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "# Predict\n",
    "lr_pred = lr.predict(X_test_scaled)\n",
    "predict = rf.predict(X_test)\n",
    "acc_score = accuracy_score(y_test, predict)\n",
    "\n",
    "# Evaluate\n",
    "print(f\"Accuracy: {accuracy_score(y_test, lr_pred) * 100:.2f}%\")\n",
    "print(classification_report(y_test, lr_pred))\n",
    "print(f\"Random forest accuracy, {acc_score}\")\n",
    "\n",
    "# the accuracy of lr is 0.80 which is higher than random forest accuracy that is 0.79.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf77621",
   "metadata": {},
   "source": [
    "Task 2 — Probability Predictions (20 mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae472a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Actual  Predicted  Prob_Died  Prob_Survived\n",
      "0       1          0       0.93           0.07\n",
      "1       0          0       0.77           0.23\n",
      "2       0          0       0.86           0.14\n",
      "3       1          1       0.09           0.91\n",
      "4       1          1       0.31           0.69\n",
      "5       1          1       0.05           0.95\n",
      "6       1          1       0.35           0.65\n",
      "7       0          0       0.91           0.09\n",
      "8       1          1       0.26           0.74\n",
      "9       1          1       0.07           0.93\n"
     ]
    }
   ],
   "source": [
    "# Get probabilities for test set\n",
    "proba = lr.predict_proba(X_test_scaled)\n",
    "\n",
    "# Create a readable DataFrame\n",
    "proba_df = pd.DataFrame({\n",
    "    \"Actual\": y_test.values,\n",
    "    \"Predicted\": lr_pred,\n",
    "    \"Prob_Died\": proba[:, 0].round(2),\n",
    "    \"Prob_Survived\": proba[:, 1].round(2)\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "print(proba_df.head(10))\n",
    "\n",
    "# 2nd passenger is the passenger where the model predicted with high confidence of 0.86\n",
    "# 0th passenger is the one where model predicted incorrectly with confidence of 0.93 for death and only 0.07 for surviving.. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3b6fd3",
   "metadata": {},
   "source": [
    "Task 3 — Compare All Three Models (15 mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bb24d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logestic regression Accuracy: 79.89%\n",
      "Random forest accuracy: 79.89%\n",
      "Decision tree accuracy: 77.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\katiy\\AppData\\Local\\Temp\\ipykernel_22740\\4254295110.py:44: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=\"Model\", y=\"Accuracy\", data=results, palette=\"Set2\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=10,random_state=42)\n",
    "dt = DecisionTreeClassifier(random_state=42, min_samples_leaf=5)\n",
    "\n",
    "# Build and train\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "rf.fit(X_train,y_train)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "lr_predict = lr.predict(X_test_scaled)\n",
    "rf_predict = rf.predict(X_test)\n",
    "dt_predict = dt.predict(X_test)\n",
    "\n",
    "#accuracy score\n",
    "lr_acc_score = accuracy_score(y_test, lr_predict)\n",
    "rf_acc_score = accuracy_score(y_test, rf_predict)\n",
    "dt_acc_score = accuracy_score(y_test, dt_predict)\n",
    "\n",
    "# Evaluate\n",
    "print(f\"logestic regression Accuracy: {lr_acc_score * 100:.2f}%\")\n",
    "print(f\"Random forest accuracy: {rf_acc_score*100:.2f}%\")\n",
    "print(f\"Decision tree accuracy: {dt_acc_score*100:.2f}%\")\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"Model\": [\"Decision Tree\", \"Random Forest\", \"Logistic Regression\"],\n",
    "    \"Accuracy\": [dt_acc_score*100, rf_acc_score*100, lr_acc_score*100]\n",
    "})\n",
    "\n",
    "sns.barplot(x=\"Model\", y=\"Accuracy\", data=results, palette=\"Set2\")\n",
    "plt.title(\"Model Comparison\")\n",
    "plt.ylabel(\"Accuracy %\")\n",
    "plt.ylim(60, 90)\n",
    "plt.show()\n",
    "\n",
    "# limiting the sample leaf to 5 does a magnificient job not only the the accuracy improved it is now same as the rf and lr and all 3 has equal that is 79.9% accuracy.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf675cf",
   "metadata": {},
   "source": [
    "Task 4 — Coefficients Analysis (15 mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ad5511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature  Coefficient\n",
      "2     Sex     2.611261\n",
      "3    Fare     0.003422\n",
      "1     Age    -0.032004\n",
      "5   Parch    -0.129331\n",
      "4   SibSp    -0.317606\n",
      "0  Pclass    -0.927792\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    \"Feature\": [\"Pclass\", \"Age\", \"Sex\", \"Fare\", \"SibSp\", \"Parch\"],\n",
    "    \"Coefficient\": model_lr.coef_[0]\n",
    "}).sort_values(\"Coefficient\", ascending=False)\n",
    "\n",
    "print(coef_df)\n",
    "\n",
    "# sex has highest positive coefficient\n",
    "# pclass has most negative coeff.\n",
    "# no it doesnot match them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c5ac6e",
   "metadata": {},
   "source": [
    "Task 5 — Predict New Passengers with Probability (20 mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2c0479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passenger 1: SURVIVED with 95.1% confidence\n",
      "Passenger 2: DIED with 94.6% confidence\n",
      "Passenger 3: SURVIVED with 89.9% confidence\n"
     ]
    }
   ],
   "source": [
    "new_passengers = pd.DataFrame({\n",
    "    \"Pclass\": [1, 3, 2],\n",
    "    \"Age\":    [25, 35, 8],\n",
    "    \"Sex\":    [1, 0, 1],\n",
    "    \"Fare\":   [100, 10, 30],\n",
    "    \"SibSp\":  [0, 1, 0],\n",
    "    \"Parch\":  [0, 2, 1]\n",
    "})\n",
    "\n",
    "# Scale using the SAME scaler — never create a new one\n",
    "new_scaled = scaler.transform(new_passengers)\n",
    "\n",
    "predictions = lr.predict(new_scaled)\n",
    "probabilities = lr.predict_proba(new_scaled)\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    status = \"SURVIVED\" if predictions[i] == 1 else \"DIED\"\n",
    "    confidence = max(probabilities[i]) * 100\n",
    "    print(f\"Passenger {i+1}: {status} with {confidence:.1f}% confidence\")\n",
    "\n",
    "# yes the confidence score makes sense for each passenger as the data suggest.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
